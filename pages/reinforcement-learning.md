---
layout: page
---
<h2><b>Foundations of Intelligent Learning Agents</b></h2>
<h3><b>Regret Minimization, Policy Evaluation and Policy Improvement for Reinforcement Learning</b></h3>

-------------------------------------------------------------------------------------------------------------------    
The assignments/projects for the course can be found [here](https://github.com/patel-shivam/CS747).  
Refer the [course website](https://www.cse.iitb.ac.in/~shivaram/teaching/cs747-a2022/index.html) for more information. 


<h3><b>Regret Minimization Algorithms for Multi Armed Bandit Formulations</b></h3>

Multi Armed Bandit Problems require regret minimization algorithms to optimize the explore-exploit tradeoff for different horizon scales.   
In the first assignment, I implemented the Epsilon-Greedy algorithms for linear regret.  
Later on, I used UCB, KL-UCB and Thompson Sampling algorithms which are in accordance with the Lai-Robbins logarithmic bound. 

Thompson Subsampling for finite stage feedback formulation. 

GLIE-ified Epsilon Greedy with quantile regret minimization for num_arms A = horizon T. 

<h3><b>Policy Evaluation, Improvement and MDP Planning</b></h3>


 


